{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with AMBench data in SciServer\n",
    "\n",
    "## Find, retrieve, and process image data for materials science\n",
    "\n",
    "#### Version 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook executes a sample query to the AMBench metadata repository via its API, then retrieves and processes the records.  The script then performs some basic image analysis and plots the results.  \n",
    "\n",
    "#### NOTE: The purpose of the notebook is to show a workflow that uses scripted access (via Python) to obtain and process data; image processing parameters and techniques were selected for this case and are not expected to be generally the best choices for other data or analysis.  Users should perform their own analyses to determine appropriate parameters and techniques for their problems of interest.\n",
    "\n",
    "The data used in this demonstration comes from the 2018 AM-Bench challenge documented at https://www.nist.gov/ambench/amb2018-02-description.\n",
    "\n",
    "The script queries the AM-Bench 2018 repository located at https://ambench.nist.gov/, then processes the returned XML-based results, processes the returned images using basic image analysis techniques, and generates plots of melt pool depths.\n",
    "\n",
    "Additional datasets and challenge problem documentation are available through the NIST Public Data Repository record at https://data.nist.gov/od/id/6D6EC9B3A4147BE2E05324570681EEC91931 with an associated publication (https://link.springer.com/article/10.1007/s40192-020-00169-1) documenting the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup: prepare the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import required packages\n",
    "\n",
    "First, we need to import packages that we will use to do the processing. Each import statement includes a comment describing what that package does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The pycdcs package is used in this notebook to query the AMBench metadata repository that contains information about the AMBench 2018 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/lmhale99/pycdcs\n",
    "# print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing packages\n",
    "import pandas\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#image_scale = 0.062   # Image scale in microns per pixel (here, 1 px = 0.062 microns)\n",
    "\n",
    "# Package to find images in the AMBench repository\n",
    "## This will allow us to find images to process\n",
    "## These packages query NIST's Configurable Data Curation System (CDCS):\n",
    "### https://www.nist.gov/itl/ssd/information-systems-group/configurable-data-curation-system-cdcs\n",
    "from cdcs import CDCS\n",
    "\n",
    "# Package to parse metadata from the AMBench repo to find where to download image files\n",
    "import lxml.etree as et\n",
    "\n",
    "# Packages to download and save image files\n",
    "import requests\n",
    "from urllib import request\n",
    "import os\n",
    "\n",
    "# Packages to do image processing once we have the images downloaded\n",
    "## From the scikit-image package; we only import the parts of the package that we need \n",
    "### scikit-image website: https://scikit-image.org/\n",
    "from skimage import io              # read/write images\n",
    "from skimage import filters         # apply filters to images\n",
    "from skimage import segmentation    # divide image into sections\n",
    "from skimage import morphology    # work with features found in image\n",
    "from skimage import measure         # measure pixel sizes of features within image\n",
    "\n",
    "### Packages to plot results\n",
    "import matplotlib.pyplot as plt   \n",
    "import matplotlib.image as mpimg  \n",
    "import matplotlib.patches as patches\n",
    "\n",
    "pandas.set_option('display.max_colwidth', None)\n",
    "\n",
    "print('Packages imported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions\n",
    "\n",
    "For some complex operations that we need to do repeatedly, it's easier to move the operations into a function call. This slows down the code slightly, but makes it much easier to read and to follow the logic of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get download links from XML returned by AMBench data repository\n",
    "# function xml_url_find(xml,searchphrase,mtype):\n",
    "## Inputs:\n",
    "### xml: contents of XML file for one of the ambench.nist.gov datasets, in string format\n",
    "### searchphrase: search phrase contained in the file name (in our case, \"BF\")\n",
    "### mtype: filetype (in our case, \"image/tiff\")\n",
    "\n",
    "## Returns:\n",
    "### A four-item list containing:\n",
    "#### (0) the name of the image file to be downloaded\n",
    "#### (1) the URL at which to download the image file\n",
    "#### (2) laser track number for that image\n",
    "#### (3) case label for that image\n",
    "\n",
    "def xml_url_find(xml,searchphrase,mtype):\n",
    "    root=et.fromstring(xml)\n",
    "    caseid=root.find('.//TraceID')[0].tag[5]\n",
    "    track=root.find('.//TrackNumber')\n",
    "    for element in root.iter('downloadURL'):\n",
    "        u=request.urlopen(element.text)\n",
    "        if (    # search XML to find searchphrase in filename and mytpe in file type\n",
    "            (searchphrase in u.info().get_filename()) \n",
    "            and (mtype in u.info().get_content_type())\n",
    "        ):\n",
    "            name=u.info().get_filename()\n",
    "            url=element.text\n",
    "            return [name,url,track.text,caseid]\n",
    "\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Find datasets to work with\n",
    "\n",
    "The AMBench data repository includes hundreds (thousands?) of datasets associated with challenges. Each dataset includes metadata describing its purpose and various conditions (inputs?) used to generate it. The actual data consists of images (stored as .tiff files) stored on a separate server at NIST. The datasets retreived from the data repository contain pointers to the image locations.\n",
    "\n",
    "This section of the notebook searches the AMBench data repository for a keyword - in this case, \"MP\" (for \"melt pool\"). It then downloads the metadata for all public datasets with your selected keyword. You can see information about each returned dataset by running the code block with the `describe_datasets = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword='MP'                # keyword to search data repository for: MP = melt pool\n",
    "describe_datasets = True    # show name and basic metadata for each dataset\n",
    "##show_dataset_xml = False     # parse xml to show full metadata for each dataset\n",
    "\n",
    "print('querying AMBench data repository for keyword {0:}...'.format(keyword))\n",
    "curator = CDCS('https://ambench.nist.gov/', username='') # query repo (CDCS) anonymously\n",
    "datasets_df = curator.query(  # search for results, return as a pandas dataframe:\n",
    "    keyword=keyword,           ## results should match this keyword\n",
    "    template='AM-Bench-2018'   ## and be associated with this tempalte\n",
    "    ) \n",
    "\n",
    "### convert all date fields to pandas date format\n",
    "for thiscol in ['creation_date', 'last_modification_date', 'last_change_date']:\n",
    "    datasets_df.loc[:, thiscol] = pandas.to_datetime(datasets_df[thiscol], errors='coerce')\n",
    "    \n",
    "### use the dataset ID as the index of the dataframe, then sort by that ID    \n",
    "datasets_df = datasets_df.set_index('id')\n",
    "\n",
    "print('Found {0:,.0f} datasets matching keyword {1:}!'.format(len(datasets_df), keyword))\n",
    "print('------------------------------------------------')\n",
    "\n",
    "if (describe_datasets):\n",
    "    for ix, thisrow in datasets_df.iterrows():\n",
    "        print('\\n')\n",
    "        print('Dataset id = {0:}'.format(ix))\n",
    "        print('\\tTitle: {0:}'.format(thisrow['title']))\n",
    "        print('\\tCreated: {0:}'.format(thisrow['creation_date'].strftime('%Y-%m-%d')))\n",
    "#         if (show_dataset_xml):\n",
    "#             show_xml(thisrow['xml_content'])\n",
    "        \n",
    "print('------------------------------------------------')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Find download links for each dataset\n",
    "\n",
    "Most of the metadata returned by the AMBench data repository is stored in XML format, easy for computers to store and process but hard for humans to read. One important piece of metadata in each dataset is a field called `downloadURL`, which gives the location where image(s) associated with that dataset can be downloaded.\n",
    "\n",
    "This notebook includes a helper function called `xml_url_find` that searches through the XML to find the download URL for each image to be processed. For this demo notebook, consider that function as a black box; if you want to learn how it works, see the function documentation in the setup step above. The `xml_url_find` function returns track, case, and image URL for each row in the dataset.\n",
    "\n",
    "Each dataset includes several images (TIFF files), each associated with a specific track and case number. The code cell below loops through each dataset returns these track and case numbers, as well as the URL where the associated image can be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchphrase='BF'  # used by function xml_url_find, don't worry about what it means now\n",
    "\n",
    "datasets_df = datasets_df.assign(   # assign blanks to values to be computed later\n",
    "    filename = np.nan, url = np.nan, track = np.nan, case = np.nan\n",
    ") \n",
    "\n",
    "### Loop through all datasets and get track/case number and URL to download image\n",
    "print('Finding URLs for images...')\n",
    "cnt = 0\n",
    "for ix, thisrow in datasets_df.iterrows():\n",
    "    if (np.mod(cnt,5) == 0):\n",
    "        print('\\tFinding URL {0:,.0f} of {1:,.0f}...'.format(cnt+1, len(datasets_df)))\n",
    "    datasets_df.loc[ix, \n",
    "                    ['filename', 'url', 'track', 'case']\n",
    "                   ] = xml_url_find(thisrow['xml_content'],'BF','image/tiff') # giving xml_url_find each xml string and searching for\n",
    "    cnt += 1\n",
    "\n",
    "\n",
    "# set track to numeric, then sort by track\n",
    "datasets_df.loc[:, 'track'] = pandas.to_numeric(\n",
    "    datasets_df['track'], downcast='integer', errors='coerce'\n",
    ")\n",
    "datasets_df = datasets_df.sort_values(by='track') \n",
    "\n",
    "# assign blanks for values to compute later\n",
    "datasets_df = datasets_df.assign(melt_pool_width_pixels = np.nan)\n",
    "datasets_df = datasets_df.assign(melt_pool_depth_pixels = np.nan)\n",
    "datasets_df = datasets_df.assign(melt_pool_width_microns = np.nan)\n",
    "datasets_df = datasets_df.assign(melt_pool_depth_microns = np.nan)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('Found download links for {0:,.0f} images!'.format(len(datasets_df['url'].dropna())))\n",
    "\n",
    "datasets_df[['track', 'case', 'url', 'filename', 'melt_pool_width_pixels', 'melt_pool_depth_pixels', 'melt_pool_width_microns', 'melt_pool_depth_microns']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Download and process images\n",
    "\n",
    "This code cell loops through each dataset you found in the previous section and performs the following operations on each (all the image processing is done using the `scikit` image processing package):\n",
    "\n",
    "1. Downloads the image from the URL you found in the last section\n",
    "1. Selects a smaller region of the image to work with (to save processing time)\n",
    "1. Segments that region using the Felzenszwalb algorithm\n",
    "1. Removes smaller regions (eliminate some background noise)\n",
    "1. Acquires a table of center coordinates for each remaining region\n",
    "1. Measures the distances from centers to the center of the entire relevant section image\n",
    "1. Finds the index number of the closest region\n",
    "1. Returns information about the closest region\n",
    "1. Uses those results to measure the width and depth of the melt pool\n",
    "1. Optionally displays the image with the relevant section marked and measured values displayed\n",
    "\n",
    "Set `show_images = True` to see each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images = True   # set to True to see what the images look like as they are found\n",
    "\n",
    "\n",
    "print('Getting images...')\n",
    "cnt = 0\n",
    "for ix, thisrow in datasets_df.iterrows():\n",
    "    #if (np.mod(cnt,5) == 0):\n",
    "    print('\\tGetting image {0:,.0f} of {1:,.0f}: track {2:,.0f} case {3:}...'.format(\n",
    "        cnt+1, len(datasets_df), thisrow['track'], thisrow['case'])\n",
    "         )\n",
    "    print(thisrow['url'])\n",
    "    # read file as an image\n",
    "    this_image = io.imread(thisrow['url'])\n",
    "    \n",
    "    # To save processing time, the segmentation algorithm is applied to only part of the image\n",
    "    ## The full image is 2832 pixels wide by 4248 pixels high\n",
    "    ### This code copies and crops the image so that the analysis region is as follows:\n",
    "    #### rectangle with coordinates 800 <= x <= 3400 , 900 <= y <= 1800\n",
    "    cropim=this_image[900:1800,800:3400]\n",
    "    \n",
    "    # Use Felezenszwalb algorithm to autosegment cropped area\n",
    "    segments=segmentation.felzenszwalb(cropim,scale=270,sigma=0.8,min_size=1000)\n",
    "\n",
    "    # Remove small objects, which are likely background noise\n",
    "    isolateim=morphology.remove_small_objects(segments,100000)\n",
    "\n",
    "    \n",
    "    # Find the center point of each segmented area, return as table\n",
    "    center=measure.regionprops_table(isolateim,properties=['centroid'])\n",
    "    \n",
    "    if (show_images):\n",
    "        center_points = []\n",
    "        if (len(center['centroid-0']) == len(center['centroid-1'])):\n",
    "            for i in range(0, len(center['centroid-0'])):\n",
    "                center_points.append(tuple((center['centroid-1'][i], center['centroid-0'][i])))\n",
    "    #            print(\"({0:}, {1:})\".format(center['centroid-1'][i], center['centroid-0'][i]))\n",
    "        else:\n",
    "            print(len(center['centroid-0']))\n",
    "            print(len(center['centroid-1']))\n",
    "        \n",
    "    # Loop through segments and calculate distance from centers to center of imagebox\n",
    "    distances=[]\n",
    "    for n in range(len(center['centroid-0'])):\n",
    "        distances.append(math.dist([center['centroid-0'][n],center['centroid-1'][n]],[450,1300]))\n",
    "#    print(distances)\n",
    "    \n",
    "        # Choose the region whose center is closest to imagebox center - that's the melt pool\n",
    "    index=distances.index(min(distances)) #Looking for the region closest to the center of the image - should be the melt pool\n",
    "    \n",
    "    object_features=measure.regionprops(isolateim)\n",
    "    \n",
    "#    qqdf = pandas.DataFrame(measure.regionprops_table(isolateim))\n",
    "    \n",
    "#     for i in range(0, len(object_features)):\n",
    "#         print(i)\n",
    "#         print(object_features[i].bbox)\n",
    "#         print('-----------')\n",
    "    \n",
    "    minr,minc,maxr,maxc = object_features[index].bbox\n",
    "#    print(minr, minc, maxr, maxc)\n",
    "\n",
    "    \n",
    "\n",
    "#     print('Melt pool width in pixels: {0:.1f}'.format(maxc-minc))\n",
    "#     print('\\tMelt pool width in microns: {0:.1f}'.format((maxc-minc)*0.062))\n",
    "    \n",
    "#     print('Melt pool depth in pixels: {0:.1f}'.format(maxr-minr))\n",
    "#     print('\\tMelt pool depth in microns: {0:.1f}'.format((maxr-minr)*0.062))\n",
    "    \n",
    "    datasets_df.loc[ix, 'melt_pool_width_pixels'] = maxc-minc\n",
    "    datasets_df.loc[ix, 'melt_pool_depth_pixels'] = maxr-minr\n",
    "    \n",
    "    datasets_df.loc[ix, 'melt_pool_width_microns'] = (maxc-minc)*0.062\n",
    "    datasets_df.loc[ix, 'melt_pool_depth_microns'] = (maxr-minr)*0.062\n",
    "    \n",
    "    if (show_images):\n",
    "        print('showing marked image...')\n",
    "        fig, ax = plt.subplots(1,1,figsize=(16,16/1.5))\n",
    "        ax.imshow(this_image)\n",
    "        ax.set_title('Track {0:.0f} case {1:}: full image'.format(thisrow['track'], thisrow['case']))\n",
    "        ax.set_xlim([0,4248])\n",
    "        ax.set_xticks(np.arange(0,4300,200))\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylim([2832,0])\n",
    "        ax.set_yticks(np.arange(2800,-200,-200))\n",
    "        ax.set_ylabel('y')\n",
    "\n",
    "\n",
    "        rect1 = patches.Rectangle((800,900), 2600, 900, linewidth=1, edgecolor='b', facecolor='none')\n",
    "        ax.add_patch(rect1)\n",
    "\n",
    "#         fig2, ax2 = plt.subplots(1,1,figsize=(16,16/1.5))\n",
    "#         #ax2.imshow(cropim)\n",
    "#         ax2.imshow(segmentation.mark_boundaries(cropim, segments))\n",
    "#         ax2.set_title('Track {0:.0f} case {1:}: cropped segmented image'.format(thisrow['track'], thisrow['case']))\n",
    "#         ax2.set_xlim([0,2600])\n",
    "#         ax2.set_xticks(np.arange(0,2700,300))\n",
    "#         ax2.set_xlabel('x')\n",
    "#         ax2.set_ylim([900,0])\n",
    "#         ax2.set_yticks(np.arange(900,-100,-100))\n",
    "#         ax2.set_ylabel('y')         \n",
    "        \n",
    "#        zim = isolateim[17]\n",
    "        fig3, ax3 = plt.subplots(1,1,figsize=(16,16/1.5))\n",
    "        #ax2.imshow(cropim)\n",
    "        ax3.imshow(segmentation.mark_boundaries(cropim, isolateim))\n",
    "#        ax3.imshow(segmentation.mark_boundaries(cropim, zim, color=(255,0,0)))\n",
    "        ax3.set_title('Track {0:.0f} case {1:}: cropped segmented isolated image'.format(thisrow['track'], thisrow['case']))\n",
    "        ax3.set_xlim([0,2600])\n",
    "        ax3.set_xticks(np.arange(0,2700,300))\n",
    "        ax3.set_xlabel('x')\n",
    "        ax3.set_ylim([900,0])\n",
    "        ax3.set_yticks(np.arange(900,-100,-100))\n",
    "        ax3.set_ylabel('y')      \n",
    "        for i in range(0, len(center_points)):\n",
    "            if (i == index):\n",
    "                ax3.annotate('{0:.0f}: {1:.1f} px'.format(i, distances[i]), center_points[i], color='red', size=24, va='center', ha='center')\n",
    "                #ax3.annotate('{0:.0f}: {1:.1f} px'.forma(object_features[i]['label'], distances[i]), center_points[i], color='red', size=24, va='center', ha='center')\n",
    "            else:\n",
    "                ax3.annotate('{0:.0f}: {1:.1f} px'.format(i, distances[i]), center_points[i], color='black', size=18, va='center', ha='center')\n",
    "#                ax3.annotate('{0:.0f}: {1:.1f} px'.format(object_features[i]['label'], distances[i]), center_points[i], color='black', size=18, va='center', ha='center')\n",
    "        ax3.annotate(\"X\", (1300,450), color='black', size=24, va='center', ha='center')\n",
    "        plt.show()\n",
    "#         rect3 = patches.Rectangle((minr,minc), maxr-minr, maxc-minc, linewidth=1, edgecolor='r', facecolor='none')\n",
    "#         ax3.add_patch(rect3)\n",
    "    cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "#qqdf\n",
    "\n",
    "# Convert track number to integer, add new columns to summary table, sort by track\n",
    "datasets_df.loc[:, 'track'] = pandas.to_numeric(\n",
    "    datasets_df['track'], downcast='integer', errors='coerce'\n",
    ")\n",
    "datasets_df = datasets_df[\n",
    "    ['title', 'track', 'case', 'melt_pool_width_pixels', 'melt_pool_depth_pixels', 'melt_pool_width_microns', 'melt_pool_depth_microns', \n",
    "     'template', 'workspace',  'creation_date', 'last_modification_date', \n",
    "     'last_change_date', 'filename', 'url', 'xml_content', 'template_title', 'user_id']\n",
    "]\n",
    "datasets_df = datasets_df.sort_values(by='track')\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "# Print melt pool width and depth for each track/case\n",
    "datasets_df[['track', 'case', 'melt_pool_width_microns', 'melt_pool_depth_microns']]\n",
    "\n",
    "\n",
    "# for i in range(0, len(isolateim[17])):\n",
    "#     print(i)\n",
    "#     print(isolateim[i])\n",
    "#     print('------')\n",
    "#print(datasets_df.head(1).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T13:09:38.676364Z",
     "iopub.status.busy": "2022-04-26T13:09:38.675524Z",
     "iopub.status.idle": "2022-04-26T13:09:38.717478Z",
     "shell.execute_reply": "2022-04-26T13:09:38.715334Z",
     "shell.execute_reply.started": "2022-04-26T13:09:38.676304Z"
    }
   },
   "source": [
    "## 4. Make plots of melt pool sizes\n",
    "\n",
    "Now that we have seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plot of melt pool widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df[['melt_pool_width_microns', 'track']].plot(y='melt_pool_width_microns',x='track',kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plot of melt pool depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df[['melt_pool_depth_microns', 'track']].plot(y='melt_pool_depth_microns',x='track',kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df.plot('melt_pool_depth_microns', 'melt_pool_depth_microns', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of what the image looks like with the bbox marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# minr,minc,maxr,maxc=bboxes[4]\n",
    "# ax.imshow(result[4][900:1800,800:3400])\n",
    "# bx = (minc, maxc, maxc, minc, minc)\n",
    "# by = (minr, minr, maxr, maxr, minr)\n",
    "# ax.plot(bx, by, '-b', linewidth=2.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# depths=[]\n",
    "# widths=[]\n",
    "# bboxes=[]\n",
    "# for im in dfres['image']:\n",
    "#     objf=draw_box_opt(im)\n",
    "#     bboxes.append(objf.bbox)\n",
    "#     minr,minc,maxr,maxc=objf.bbox #using the bbox drawn around the melt pool to find width and depth\n",
    "#     widths.append((maxc-minc)*(0.062)) #using the conversion given in the CDCS comment above the images to convert to mm (1 pixel=0.062 microns)\n",
    "#     depths.append((maxr-minr)*(0.062))\n",
    "# dat={'width':widths,'depth':depths,'track':trace,'case':case}\n",
    "# dfmp=pandas.DataFrame(dat)\n",
    "# dfmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fig = plt.subplots(1,1)\n",
    "\n",
    "# for ix, thisrow in datasets_df.iterrows():\n",
    "    \n",
    "#     print('Getting image for track {0:,.0f} case {1:}...'.format(thisrow['track'], thisrow['case']))\n",
    "#     this_image = io.imread(thisrow['url'])\n",
    "\n",
    "#     print('\\tmeasuring melt pool in image...')\n",
    "#     minr,minc,maxr,maxc = draw_box_opt(this_image).bbox #using the bbox drawn around the melt pool to find width and depth\n",
    "\n",
    "#     datasets_df.loc[ix, 'melt_pool_width_microns'] = (maxc-minc)*(0.062)\n",
    "#     datasets_df.loc[ix, 'melt_pool_depth_microns'] = (maxr-minr)*(0.062)\n",
    "    \n",
    "#     print('\\tshowing marked image...')    \n",
    "#     fig, ax = plt.subplots(1,1)\n",
    "    \n",
    "#     bx = (minc, maxc, maxc, minc, minc)\n",
    "#     by = (minr, minr, maxr, maxr, minr)\n",
    "    \n",
    "#     ax.imshow(this_image[900:1800,800:3400])\n",
    "#     ax.plot(bx, by, '-b', linewidth=2.5)\n",
    "#     ax.set_title('Track {0:.0f} case {1:} (width = {2:.1f} µm, depth = {3:.1f} µm)'.format(thisrow['track'], thisrow['case'], datasets_df.loc[ix]['melt_pool_width_microns'], datasets_df.loc[ix]['melt_pool_depth_microns']))\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "#     #using the conversion given in the CDCS comment above the images to convert to mm (1 pixel=0.062 microns)\n",
    "# # objf\n",
    "# #datasets_df.head(2)\n",
    "# #plt.show()\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_xml(xml):\n",
    "#     print('xml tree:')\n",
    "#     print('---------')\n",
    "#     root = et.fromstring(xml)\n",
    "#     for i in range(0, len(root)):\n",
    "#         if (len(root[i]) <= 1):\n",
    "#             print('{0:.0f}. {1:}: {2:}'.format(i, root[i].tag, root[i].text))\n",
    "#         else:\n",
    "#             print('{0:.0f}. {1:} has {2:.0f} elements!'.format(i, root[i].tag, len(root[i])))\n",
    "#             for j in range(0, len(root[i])):\n",
    "#                 if (len(root[i][j]) <= 1):\n",
    "#                     print('\\t{0:.0f}.{1:.0f}. {2:}: {3:}'.format(i, j, root[i][j].tag, root[i][j].text))\n",
    "#                 else:\n",
    "#                     print('\\t{0:.0f}.{1:.0f}. {2:} has {3:.0f} elements!'.format(i, j, root[i][j].tag, len(root[i][j])))\n",
    "#                     for k in range(0, len(root[i][j])):\n",
    "#                         if (len(root[i][j][k]) <= 1):\n",
    "#                             print('\\t\\t{0:.0f}.{1:.0f}.{2:.0f}. {3:}: {4:}'.format(i, j, k, root[i][j][k].tag, root[i][j][k].text))\n",
    "#                         else:\n",
    "#                             print('\\t\\t\\t{0:.0f}.{1:.0f}.{2:.0f}. {3:} has {4:.0f} elements!'.format(i, j, k, root[i][j][k].tag, len(root[i][j][k])))\n",
    "#                             for l in range(0, len(root[i][j][k])):\n",
    "#                                 if (len(root[i][j][k][l]) <= 1):\n",
    "#                                     print('\\t\\t\\t{0:.0f}.{1:.0f}.{2:.0f}.{3:.0f}. {4:}: {5:}'.format(i, j, k, l, root[i][j][k][l].tag, root[i][j][k][l].text))\n",
    "#                                 else:\n",
    "#                                     for m in range(0, len(root[i][j][k][l])):\n",
    "#                                         if (len(root[i][j][k][l][m]) <= 1):\n",
    "#                                             print('\\t\\t\\t\\t{0:.0f}.{1:.0f}.{2:.0f}.{3:.0f}.{4:.0f}. {5:}: {6:}'.format(i, j, k, l, m, root[i][j][k][l][m].tag, root[i][j][k][l][m].text))\n",
    "#                                         else:\n",
    "#                                             print('\\t\\t\\t\\t{0:.0f}.{1:.0f}.{2:.0f}.{3:.0f}.{4:.0f}. {5:} has {6:.0f} elements!'.format(i, j, k, l, m, root[i][j][k][l][m].tag, len(root[i][j][k][l][m])))\n",
    "\n",
    "\n",
    "###### JR: since we are getting and processing images one by one, we no longer need this, keeping for reference\n",
    "# #Given an xml string like the one returned by CDCS_xml, will return a dataframe of download links for the files on the AMBench\n",
    "# #page (includes name, description, comments, etc.)\n",
    "# def CDCS_downloads(xml):\n",
    "#     root=et.fromstring(xml)\n",
    "#     result=[]\n",
    "#     for element in root.iter('downloadURL'):\n",
    "#         entry={}\n",
    "#         for e in element.getparent():\n",
    "#             entry[e.tag]=e.text\n",
    "#         result.append(entry)\n",
    "#     df=py.DataFrame.from_dict(result,orient='columns')\n",
    "#     return df        \n",
    "\n",
    "\n",
    "# #### draw_box_opt\n",
    "######## JR: we are now doing these steps in the main body, keeping this function commented out for reference\n",
    "# # This method (1) crops the melt pool images (to reduce runtime), (2) applies the felzenszwalb segmentation algorithm to the image, (3) removes smaller regions (eliminate some background noise), (4) acquires a table of center coordinates for the remaining regions, (5) measures the distances from centers to the center of the image, (6) finds the index number of the closest region, (7) returns information about the closes region\n",
    "\n",
    "# # Parameters:\n",
    "# # - image to be analyzed\n",
    "\n",
    "# # Returns:\n",
    "# # - list of RegionProperties related to the melt pool region\n",
    "# def draw_box_opt(image):\n",
    "#     cropim=image[900:1800,800:3400] #cropping so that there's less pixels to cover - incredibly slow if left at original size\n",
    "#     segments=segmentation.felzenszwalb(cropim,scale=270,sigma=0.8,min_size=1000)\n",
    "#     isolateim=morphology.remove_small_objects(segments,100000)\n",
    "#     center=measure.regionprops_table(isolateim,properties=['centroid']) #table of information about the center points of regions\n",
    "#     distances=[]\n",
    "#     for n in range(len(center['centroid-0'])):\n",
    "#         distances.append(math.dist([center['centroid-0'][n],center['centroid-1'][n]],[450,1300]))\n",
    "#     index=distances.index(min(distances)) #Looking for the region closest to the center of the image - should be the melt pool\n",
    "#     object_features=measure.regionprops(isolateim)\n",
    "#     return object_features[index] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
